# MahaRERA Project Scraper

A comprehensive web scraper for extracting real estate project data from the Maharashtra Real Estate Regulatory Authority (MahaRERA) website. This scraper extracts detailed project information from individual project pages with advanced CAPTCHA solving capabilities.

## üöÄ Features

- **Advanced CAPTCHA Solving**: OCR-based automatic CAPTCHA recognition using Tesseract
- **Comprehensive Data Extraction**: Extracts 43+ detailed fields per project
- **JavaScript Support**: Uses Playwright with Firefox for dynamic content handling
- **Resume Functionality**: Can resume from where it left off using processed records tracking
- **Parallel Processing Ready**: Designed for cloud deployment with multiple instances
- **Robust Error Handling**: Comprehensive logging and error recovery
- **CSV Export**: Structured data export with proper column ordering
- **Anti-Detection**: Stealth techniques to avoid bot detection

## üìä Data Fields Extracted

The scraper extracts the following 43+ fields per project:

### Registration Details
- Registration Number
- Date of Registration
- Project Name
- Project Status
- Project Type
- Project Location
- Proposed Completion Date

### Planning & Land Details
- Planning Authority
- Full Name of Planning Authority
- Final Plot Bearing
- Total Land Area
- Land Area Applied
- Permissible Built-up Area
- Sanctioned Built-up Area
- Aggregate Open Space

### Project Address
- Complete Project Address

### Promoter Information
- Promoter Type
- Name of Partnership
- Promoter Official Address
- Partner Details (Names & Designations)
- Past Project Experience
- Authorised Signatory Details

### Professional Details
- Architect Information
- Engineer Information
- Other Professionals
- Promoter Project Member Number
- SRO Membership Type

### Additional Details
- Landowner Type
- Investor Information
- Litigation Details
- Building Specifications
- Parking Details
- Bank Information
- Complaint Details
- Real Estate Agents

## üõ†Ô∏è Prerequisites

- **Python 3.8+**
- **Tesseract OCR** (for CAPTCHA solving)
- **Firefox Browser** (for Playwright)

## üì¶ Installation

### 1. Clone the Repository
```bash
git clone <repository-url>
cd scraper
```

### 2. Create Virtual Environment
```bash
python -m venv maharera_env
source maharera_env/bin/activate  # On Windows: maharera_env\Scripts\activate
```

### 3. Install Python Dependencies
```bash
pip install playwright pandas pillow pytesseract opencv-python numpy
```

### 4. Install Playwright Browsers
```bash
playwright install firefox
```

### 5. Install Tesseract OCR

**On macOS:**
```bash
brew install tesseract
```

**On Ubuntu/Debian:**
```bash
sudo apt-get update
sudo apt-get install tesseract-ocr
```

**On Windows:**
Download from: https://github.com/UB-Mannheim/tesseract/wiki

## üöÄ Usage

### Basic Usage
```bash
python main.py
```

### Input Requirements
The scraper expects a CSV file at `./phase-1/phase1_preview_links.csv` with columns:
- `reg_no`: Registration number
- `view_link`: Direct link to project details page

### Output
- **CSV File**: `maharera_complete_data.csv` with all extracted data
- **Logs**: Console output with detailed progress information

## üìÅ Project Structure

```
scraper/
‚îú‚îÄ‚îÄ main.py                    # Main scraper orchestration
‚îú‚îÄ‚îÄ modules/
‚îÇ   ‚îú‚îÄ‚îÄ captcha_solver.py     # OCR-based CAPTCHA solving
‚îÇ   ‚îî‚îÄ‚îÄ data_extracter.py     # Comprehensive data extraction (839 lines)
‚îú‚îÄ‚îÄ phase-1/
‚îÇ   ‚îú‚îÄ‚îÄ phase1_preview_links.csv  # Input data source
‚îÇ   ‚îî‚îÄ‚îÄ maharera_phase1_scraper.py # Phase 1 scraper
‚îú‚îÄ‚îÄ maharera_env/             # Virtual environment
‚îú‚îÄ‚îÄ maharera_complete_data.csv # Output file
‚îî‚îÄ‚îÄ README.md                 # This file
```

## ü§ù Contributing

Feel free to submit issues, feature requests, or pull requests to improve the scraper.

## üìÑ License

This project is for educational and research purposes. Please ensure compliance with applicable laws and website terms of service.

## üí¨ Support

For issues or questions:
1. Check the troubleshooting section
2. Review the log files for error details
3. Ensure all dependencies are properly installed
4. Verify the website is accessible and functioning 

##  Technical Stack

| Component | Technology | Purpose |
|-----------|------------|---------|
| **Browser Automation** | Playwright + Firefox | Web scraping & JavaScript handling |
| **Data Processing** | Pandas + NumPy | Data manipulation & analysis |
| **Computer Vision** | OpenCV + Tesseract | CAPTCHA image processing & OCR |
| **Async Processing** | Asyncio | Concurrent operations |
| **Image Handling** | PIL (Pillow) | Image processing |
| **Data Storage** | CSV | Structured data export |

## ‚òÅÔ∏è Cloud Deployment

### Railway.app (Recommended)
```bash
# 1. Create requirements.txt
echo "playwright==1.40.0
pandas==2.1.4
Pillow==10.1.0
pytesseract==0.3.10
opencv-python==4.8.1.78
numpy==1.24.3" > requirements.txt

# 2. Deploy to Railway
# - Sign up at railway.app
# - Connect GitHub repository
# - Deploy automatically
```

### Parallel Processing
The scraper is designed for parallel execution:
- **Single Instance**: Multiple workers in same process
- **Multiple Instances**: Different cloud instances processing different chunks
- **Resume Capability**: Tracks processed records to avoid duplicates

## üêõ Troubleshooting

### Common Issues

1. **CAPTCHA Solving Fails**
   - Ensure Tesseract is properly installed
   - Check image quality and preprocessing
   - Verify OCR configuration

2. **Browser Issues**
   - Ensure Firefox is installed
   - Run `playwright install firefox`
   - Check system dependencies

3. **Memory Issues**
   - Process data in smaller chunks
   - Use headless mode for cloud deployment
   - Monitor system resources

4. **Rate Limiting**
   - Add delays between requests
   - Use multiple instances with different IPs
   - Implement exponential backoff

### Debug Mode
For debugging, modify `main.py`:
```python
# Change headless=False to see browser
browser = await p.firefox.launch(headless=False)
```

## üìà Performance

- **Processing Speed**: ~30-60 seconds per record
- **Success Rate**: ~95% with CAPTCHA solving
- **Data Fields**: 43+ extracted per project
- **Total Capacity**: 43,000+ projects
- **Parallel Processing**: 10+ instances supported

## ‚öñÔ∏è Legal & Ethical Considerations

- **Respect robots.txt**: Follow website terms
- **Rate Limiting**: Built-in delays to avoid server overload
- **Data Usage**: Ensure compliance with data protection laws
- **Terms of Service**: Review website terms before scraping

## ü§ù Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Test thoroughly
5. Submit a pull request

## üìÑ License

This project is for educational and research purposes. Please ensure compliance with applicable laws and website terms of service.

## üÜò Support

For issues or questions:
1. Check the troubleshooting section
2. Review console logs for error details
3. Ensure all dependencies are properly installed
4. Verify the website is accessible

---

**Note**: This scraper is designed for production use with cloud deployment capabilities and advanced error handling. 